{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.datasets import imdb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train), (x_test, y_test) = imdb.load_data(num_words = max_features) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-805e3002721e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mindex_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mindex_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "index_word = {i: word for word, i in word_index.items()}\n",
    "index_word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'wonder', 'own', 'as', 'by', 'is', 'sequence', 'i', 'i', 'jars', 'roses', 'to', 'of', 'hollywood', 'br', 'of', 'down', 'shouting', 'getting', 'boring', 'of', 'ever', 'it', 'sadly', 'sadly', 'sadly', 'i', 'i', 'was', 'then', 'does', \"don't\", 'close', 'faint', 'after', 'one', 'carry', 'as', 'by', 'are', 'be', 'favourites', 'all', 'family', 'turn', 'in', 'does', 'as', 'three', 'part', 'in', 'another', 'some', 'to', 'be', 'probably', 'with', 'world', 'uncaring', 'her', 'an', 'have', 'faint', 'beginning', 'own', 'as', 'is', 'sequence']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print([index_word.get(word, ' ') for word in x_test[0]])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen = maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = maxlen)\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = Sequential()\n",
    "Model.add(Embedding(max_features, 128))\n",
    "Model.add(LSTM(128, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "Model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = 'sgd',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 74s 3ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 1.1535 - val_acc: 0.8127\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 90s 4ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 1.1615 - val_acc: 0.8132\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 73s 3ms/step - loss: 0.0038 - acc: 0.9990 - val_loss: 1.1658 - val_acc: 0.8140\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 73s 3ms/step - loss: 0.0040 - acc: 0.9989 - val_loss: 1.1709 - val_acc: 0.8137\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 73s 3ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 1.1722 - val_acc: 0.8142\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 72s 3ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 1.1702 - val_acc: 0.8143\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 71s 3ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 1.1703 - val_acc: 0.8143\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 74s 3ms/step - loss: 0.0029 - acc: 0.9995 - val_loss: 1.1729 - val_acc: 0.8148\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 75s 3ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 1.1835 - val_acc: 0.8151\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 83s 3ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 1.1924 - val_acc: 0.8146\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 72s 3ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 1.1951 - val_acc: 0.8148\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 73s 3ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 1.1932 - val_acc: 0.8151\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 72s 3ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 1.2015 - val_acc: 0.8156\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 74s 3ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 1.1997 - val_acc: 0.8153\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 79s 3ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 1.2008 - val_acc: 0.8152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc39558def0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit(x_train, y_train,\n",
    "         batch_size = batch_size,\n",
    "         epochs = 15,\n",
    "         validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 11s 446us/step\n"
     ]
    }
   ],
   "source": [
    "score, accur = Model.evaluate(x_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 1.2007602597666531\n",
      "accuracy 0.81524\n"
     ]
    }
   ],
   "source": [
    "print(\"score\", score)\n",
    "print(\"accuracy\", accur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'movie', 'was', 'a', 'great', 'waste', 'of', 'my', 'time']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = \"the movie was a great waste of my time\"\n",
    "words = words.split()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 20, 16, 6, 87, 437, 7, 61, 58]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = []\n",
    "for word in words:\n",
    "    if word not in word_index: \n",
    "        review.append(2)\n",
    "    else:\n",
    "        review.append(word_index[word]+3) \n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  7, 61, 58]]], dtype=int32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sequence.pad_sequences([words], truncating='pre', padding='pre', maxlen = maxlen)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.5349317e-01],\n",
       "       [1.6010350e-01],\n",
       "       [3.3176020e-01],\n",
       "       [6.0706151e-01],\n",
       "       [9.6460319e-01],\n",
       "       [1.2705733e-04],\n",
       "       [5.2351439e-01],\n",
       "       [3.0047601e-01],\n",
       "       [2.4468157e-01]], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = Model.predict(review)\n",
    "print(\"%0.4f\" % prediction[0][0])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'wonder', 'own', 'as', 'by', 'is', 'sequence', 'i', 'i', 'jars', 'roses', 'to', 'of', 'hollywood', 'br', 'of', 'down', 'shouting', 'getting', 'boring', 'of', 'ever', 'it', 'sadly', 'sadly', 'sadly', 'i', 'i', 'was', 'then', 'does', \"don't\", 'close', 'faint', 'after', 'one', 'carry', 'as', 'by', 'are', 'be', 'favourites', 'all', 'family', 'turn', 'in', 'does', 'as', 'three', 'part', 'in', 'another', 'some', 'to', 'be', 'probably', 'with', 'world', 'uncaring', 'her', 'an', 'have', 'faint', 'beginning', 'own', 'as', 'is', 'sequence']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print([index_word.get(word,' ') for word in x_test[0]])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
