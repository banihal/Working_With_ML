{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Project.ipynb",
      "provenance": [],
      "mount_file_id": "1n5JNEbswCjH7MhPYlUCOR1AuqZTBRjBq",
      "authorship_tag": "ABX9TyOq2P06pqlqcX+PtVkml4kR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/banihal/Working_With_ML/blob/master/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQTx1xdxNB8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "484f23fe-f28c-4134-eafc-0ba902a34ba7"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot \n",
        "import cv2\n",
        "print(os.listdir('../content/drive/My Drive/data'))\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Scentless Mayweed', 'Common Chickweed', 'Maize', 'Common wheat', 'Sugar beet', 'Loose Silky-bent', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Fat Hen', 'Cleavers', 'Charlock', 'Black-grass']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Lz2V3ZPfhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_img = []\n",
        "label = []\n",
        "\n",
        "for dir_path in glob.glob('../content/drive/My Drive/data/*'):\n",
        "  image_label = dir_path.split('/')[-1]\n",
        "  for image_path in glob.glob(os.path.join(dir_path, '*.png')):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (64,64))\n",
        "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
        "    training_img.append(image)\n",
        "    label.append(image_label)\n",
        "\n",
        "training_img = np.array(training_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF55I-sMPhPs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "04cabbef-5307-448d-e7f1-04954923eea8"
      },
      "source": [
        "label_to_id = {v:k for k,v in enumerate(np.unique(label))}\n",
        "id_to_label = {v:k for k,v in label_to_id.items()}\n",
        "label_to_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Black-grass': 0,\n",
              " 'Charlock': 1,\n",
              " 'Cleavers': 2,\n",
              " 'Common Chickweed': 3,\n",
              " 'Common wheat': 4,\n",
              " 'Fat Hen': 5,\n",
              " 'Loose Silky-bent': 6,\n",
              " 'Maize': 7,\n",
              " 'Scentless Mayweed': 8,\n",
              " 'Shepherds Purse': 9,\n",
              " 'Small-flowered Cranesbill': 10,\n",
              " 'Sugar beet': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaFmXoNvfuNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_label_id = np.array([label_to_id[x] for x in label])\n",
        "Y = np.array(training_label_id)\n",
        "Y = to_categorical(Y, num_classes = 12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rehwcNg8fxGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers.core import Dense,Dropout,Activation\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers.pooling import AveragePooling2D,GlobalAveragePooling2D\n",
        "from keras.layers import Input,Concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import RMSprop,Adamax\n",
        "import keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,LearningRateScheduler,EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcQDFQ9ofxpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_layer(x,concat_axis,nb_filter,dropout_rate=None,weight_decay=1E-4):\n",
        "    x = BatchNormalization(axis=concat_axis,\n",
        "                          gamma_regularizer=l2(weight_decay),\n",
        "                          beta_regularizer=l2(weight_decay))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(nb_filter,(3,3),padding='same',kernel_regularizer=l2(weight_decay),use_bias=False)(x)\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNIzFXULf4NR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transition_layer(x,concat_axis,nb_filter,dropout_rate=None,weight_decay=1E-4):\n",
        "    x = BatchNormalization(axis=concat_axis,\n",
        "                          gamma_regularizer=l2(weight_decay),\n",
        "                          beta_regularizer=l2(weight_decay))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(nb_filter,(1,1),padding='same',kernel_regularizer=l2(weight_decay),use_bias=False)(x)\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "    x = AveragePooling2D((2,2),strides=(2,2))(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdhXTgBjf63W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolution_block(x, nb_channels, dropout_rate=None, bottleneck=False, weight_decay=1e-4):\n",
        "    \"\"\"\n",
        "    Creates a convolution block consisting of BN-ReLU-Conv.\n",
        "    Optional: bottleneck, dropout\n",
        "    \"\"\"\n",
        "    \n",
        "    # Bottleneck\n",
        "    if bottleneck:\n",
        "        bottleneckWidth = 4\n",
        "        x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2D(nb_channels * bottleneckWidth, (1, 1), use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n",
        "        # Dropout\n",
        "        if dropout_rate:\n",
        "            x = Dropout(dropout_rate)(x)\n",
        "    \n",
        "    # Standard (BN-ReLU-Conv)\n",
        "    x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(nb_channels, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n",
        "    \n",
        "    # Dropout\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFQXH_dw8DIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def denseblock(x,concat_axis,nb_channels,nb_layers,growth_rate,dropout_rate=None,weight_decay=1E-4):\n",
        "    list_features = [x]\n",
        "    for i in range(nb_layers):\n",
        "        x = conv_layer(x,concat_axis,growth_rate,dropout_rate=None,weight_decay=1E-4)\n",
        "        list_features.append(x)\n",
        "        x = Concatenate(axis=concat_axis)(list_features)\n",
        "        nb_channels += growth_rate\n",
        "    return x,nb_channels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OnRcP7tf9K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DenseNet(input_shape=None, dense_blocks=3, dense_layers=-1, growth_rate=12, nb_classes=None, dropout_rate=None,\n",
        "             bottleneck=False, compression=1.0, weight_decay=1e-4, depth=40):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    input_shape  : shape of the input images. E.g. (28,28,1) for MNIST    \n",
        "    dense_blocks : amount of dense blocks that will be created (default: 3)    \n",
        "    dense_layers : number of layers in each dense block. You can also use a list for numbers of layers [2,4,3]\n",
        "                   or define only 2 to add 2 layers at all dense blocks. -1 means that dense_layers will be calculated\n",
        "                   by the given depth (default: -1)\n",
        "    growth_rate  : number of filters to add per dense block (default: 12)\n",
        "    nb_classes   : number of classes\n",
        "    dropout_rate : defines the dropout rate that is accomplished after each conv layer (except the first one).\n",
        "                   In the paper the authors recommend a dropout of 0.2 (default: None)\n",
        "    bottleneck   : (True / False) if true it will be added in convolution block (default: False)\n",
        "    compression  : reduce the number of feature-maps at transition layer. In the paper the authors recomment a compression\n",
        "                   of 0.5 (default: 1.0 - will have no compression effect)\n",
        "    weight_decay : weight decay of L2 regularization on weights (default: 1e-4)\n",
        "    depth        : number or layers (default: 40)\n",
        " \n",
        "    Returns:\n",
        "    Model        : A Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    if nb_classes==None:\n",
        "        raise Exception('Please define number of classes (e.g. num_classes=10). This is required for final softmax.')\n",
        "    \n",
        "    if compression <=0.0 or compression > 1.0:\n",
        "        raise Exception('Compression have to be a value between 0.0 and 1.0. If you set compression to 1.0 it will be turn off.')\n",
        "    \n",
        "    if type(dense_layers) is list:\n",
        "        if len(dense_layers) != dense_blocks:\n",
        "            raise AssertionError('Number of dense blocks have to be same length to specified layers')\n",
        "    elif dense_layers == -1:\n",
        "        if bottleneck:\n",
        "            dense_layers = (depth - (dense_blocks + 1))/dense_blocks // 2\n",
        "        else:\n",
        "            dense_layers = (depth - (dense_blocks + 1))//dense_blocks\n",
        "        dense_layers = [int(dense_layers) for _ in range(dense_blocks)]\n",
        "    else:\n",
        "        dense_layers = [int(dense_layers) for _ in range(dense_blocks)]\n",
        "\n",
        "    if K.common.image_dim_ordering() == \"th\":\n",
        "        concat_axis = 1\n",
        "    elif K.common.image_dim_ordering() == \"tf\":\n",
        "        concat_axis = -1\n",
        "        \n",
        "    img_input = Input(shape=input_shape)\n",
        "    nb_channels = growth_rate * 2\n",
        "\n",
        "    \n",
        "    print('Creating DenseNet')\n",
        "    print('#############################################')\n",
        "    print('Dense blocks: %s' % dense_blocks)\n",
        "    print('Layers per dense block: %s' % dense_layers)\n",
        "    print('#############################################')\n",
        "    \n",
        "    # Initial convolution layer\n",
        "    x = Conv2D(nb_channels, (3,3), padding='same',strides=(1,1),\n",
        "                      use_bias=False, kernel_regularizer=l2(weight_decay))(img_input)\n",
        "    \n",
        "    # Building dense blocks\n",
        "    for block in range(dense_blocks):\n",
        "        \n",
        "        # Add dense block\n",
        "        x, nb_channels = dense_block(x, dense_layers[block], nb_channels, growth_rate, dropout_rate, bottleneck, weight_decay)\n",
        "        \n",
        "        if block < dense_blocks - 1:  # if it's not the last dense block\n",
        "            # Add transition_block\n",
        "            x = transition_layer(x, nb_channels, dropout_rate, compression, weight_decay)\n",
        "            nb_channels = int(nb_channels * compression)\n",
        "    \n",
        "    x = BatchNormalization(gamma_regularizer=l2(weight_decay), beta_regularizer=l2(weight_decay))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    \n",
        "    x = Dense(nb_classes, activation='softmax', kernel_regularizer=l2(weight_decay), bias_regularizer=l2(weight_decay))(x)\n",
        "    \n",
        "    densenet = Model(inputs=[img_input], outputs=[x], name=\"DenseNet\")\n",
        "    \n",
        "    return densenet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCiymQcJgAsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(training_img, Y, test_size = 0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP8_0qp5gDE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =         Densenet(nb_classes=12,\n",
        "                          img_dim=(64,64,3),\n",
        "                          depth = 34,\n",
        "                          nb_dense_block = 6,\n",
        "                          growth_rate=12,\n",
        "                          nb_filter=32,\n",
        "                          dropout_rate=0.25,\n",
        "                          weight_decay=1E-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynzYDCHqgK6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adamax(),\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqIp2_VVgTbb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0ddd5e9b-3623-4d4d-8870-e184c080cb1a"
      },
      "source": [
        "model_filepath = 'model.h5'\n",
        "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=1e-5, patience=2, verbose=1)\n",
        "msave = ModelCheckpoint(model_filepath, save_best_only=True)\n",
        "aug = ImageDataGenerator(rotation_range=180, width_shift_range=0.1, \\\n",
        "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\\\n",
        "    horizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL_tpnjPgWGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61adf7b1-65b6-4192-8d81-43a7a9e03e0e"
      },
      "source": [
        "model.fit(aug.flow(X_train ,Y_train, batch_size=16),\n",
        "               validation_data = (X_test,Y_test),\n",
        "               epochs = 30,\n",
        "               callbacks=[lr_reduce,annealer,msave],\n",
        "               verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "207/207 [==============================] - 131s 632ms/step - loss: 3.5675 - accuracy: 0.5304 - val_loss: 3.3291 - val_accuracy: 0.5543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/30\n",
            "207/207 [==============================] - 108s 521ms/step - loss: 2.9915 - accuracy: 0.6799 - val_loss: 3.0641 - val_accuracy: 0.6286\n",
            "Epoch 3/30\n",
            "207/207 [==============================] - 107s 518ms/step - loss: 2.7148 - accuracy: 0.7493 - val_loss: 3.2106 - val_accuracy: 0.6457\n",
            "Epoch 4/30\n",
            "207/207 [==============================] - 108s 521ms/step - loss: 2.5240 - accuracy: 0.7877 - val_loss: 2.8532 - val_accuracy: 0.6971\n",
            "Epoch 5/30\n",
            "207/207 [==============================] - 108s 523ms/step - loss: 2.3975 - accuracy: 0.7989 - val_loss: 2.3907 - val_accuracy: 0.8171\n",
            "Epoch 6/30\n",
            "207/207 [==============================] - 108s 522ms/step - loss: 2.2633 - accuracy: 0.8306 - val_loss: 2.4459 - val_accuracy: 0.7657\n",
            "Epoch 7/30\n",
            "207/207 [==============================] - 108s 522ms/step - loss: 2.1676 - accuracy: 0.8493 - val_loss: 2.0971 - val_accuracy: 0.8571\n",
            "Epoch 8/30\n",
            "207/207 [==============================] - 108s 522ms/step - loss: 2.0892 - accuracy: 0.8632 - val_loss: 2.0987 - val_accuracy: 0.8686\n",
            "Epoch 9/30\n",
            "207/207 [==============================] - 108s 523ms/step - loss: 2.0460 - accuracy: 0.8620 - val_loss: 2.0255 - val_accuracy: 0.8686\n",
            "Epoch 10/30\n",
            "207/207 [==============================] - 108s 524ms/step - loss: 1.9596 - accuracy: 0.8837 - val_loss: 2.1485 - val_accuracy: 0.8171\n",
            "Epoch 11/30\n",
            "207/207 [==============================] - 108s 523ms/step - loss: 1.9186 - accuracy: 0.8898 - val_loss: 2.1030 - val_accuracy: 0.8343\n",
            "Epoch 12/30\n",
            "207/207 [==============================] - 108s 521ms/step - loss: 1.8983 - accuracy: 0.8919 - val_loss: 1.8979 - val_accuracy: 0.9029\n",
            "Epoch 13/30\n",
            "207/207 [==============================] - 108s 520ms/step - loss: 1.8318 - accuracy: 0.9049 - val_loss: 1.8914 - val_accuracy: 0.9086\n",
            "Epoch 14/30\n",
            "207/207 [==============================] - 108s 522ms/step - loss: 1.8094 - accuracy: 0.9115 - val_loss: 1.8362 - val_accuracy: 0.9200\n",
            "Epoch 15/30\n",
            "207/207 [==============================] - 108s 522ms/step - loss: 1.7836 - accuracy: 0.9115 - val_loss: 1.8936 - val_accuracy: 0.8800\n",
            "Epoch 16/30\n",
            "207/207 [==============================] - 108s 522ms/step - loss: 1.7555 - accuracy: 0.9160 - val_loss: 1.8556 - val_accuracy: 0.9143\n",
            "Epoch 17/30\n",
            "207/207 [==============================] - 108s 522ms/step - loss: 1.7506 - accuracy: 0.9139 - val_loss: 1.7987 - val_accuracy: 0.8914\n",
            "Epoch 18/30\n",
            "207/207 [==============================] - 108s 520ms/step - loss: 1.7207 - accuracy: 0.9191 - val_loss: 1.7761 - val_accuracy: 0.9086\n",
            "Epoch 19/30\n",
            "207/207 [==============================] - 108s 521ms/step - loss: 1.7100 - accuracy: 0.9242 - val_loss: 1.8085 - val_accuracy: 0.9086\n",
            "Epoch 20/30\n",
            "207/207 [==============================] - 108s 523ms/step - loss: 1.7043 - accuracy: 0.9230 - val_loss: 1.7141 - val_accuracy: 0.9429\n",
            "Epoch 21/30\n",
            "207/207 [==============================] - 108s 523ms/step - loss: 1.6694 - accuracy: 0.9396 - val_loss: 1.7100 - val_accuracy: 0.9371\n",
            "Epoch 22/30\n",
            "207/207 [==============================] - 109s 525ms/step - loss: 1.6742 - accuracy: 0.9314 - val_loss: 1.7216 - val_accuracy: 0.9314\n",
            "Epoch 23/30\n",
            "207/207 [==============================] - 109s 526ms/step - loss: 1.6521 - accuracy: 0.9390 - val_loss: 1.7167 - val_accuracy: 0.9200\n",
            "Epoch 24/30\n",
            "207/207 [==============================] - 109s 527ms/step - loss: 1.6421 - accuracy: 0.9414 - val_loss: 1.6632 - val_accuracy: 0.9543\n",
            "Epoch 25/30\n",
            "207/207 [==============================] - 109s 527ms/step - loss: 1.6306 - accuracy: 0.9396 - val_loss: 1.6623 - val_accuracy: 0.9543\n",
            "Epoch 26/30\n",
            "207/207 [==============================] - 109s 527ms/step - loss: 1.6270 - accuracy: 0.9378 - val_loss: 1.6794 - val_accuracy: 0.9429\n",
            "Epoch 27/30\n",
            "207/207 [==============================] - 109s 529ms/step - loss: 1.6202 - accuracy: 0.9393 - val_loss: 1.6753 - val_accuracy: 0.9543\n",
            "Epoch 28/30\n",
            "207/207 [==============================] - 109s 529ms/step - loss: 1.6229 - accuracy: 0.9408 - val_loss: 1.6894 - val_accuracy: 0.9314\n",
            "Epoch 29/30\n",
            "207/207 [==============================] - 110s 529ms/step - loss: 1.6157 - accuracy: 0.9396 - val_loss: 1.6482 - val_accuracy: 0.9543\n",
            "Epoch 30/30\n",
            "207/207 [==============================] - 109s 528ms/step - loss: 1.6127 - accuracy: 0.9420 - val_loss: 1.6604 - val_accuracy: 0.9486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd190e83668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y3x3q5e7dgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hue_xRSI7iCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irxH9lDk7q3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYvS_Smq-C9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FPQiLxO-F1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}